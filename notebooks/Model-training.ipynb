{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training + Pipeline + Feature Scaling + TrainTestSplit\n",
    "\n",
    "#### Feature Scaling \n",
    "Feature scaling is a preprocessing step commonly used in machine learning to standardize or normalize the features of a dataset. It helps to ensure that all features are on a similar scale, which can be beneficial for many machine learning algorithms.\n",
    "\n",
    "Standardization transforms the data so that it has zero mean and unit variance. It subtracts the mean of each feature and divides by its standard deviation. This technique does not bound the values to a specific range.\n",
    "#### TrainTestSplit\n",
    "It is common practice to split your dataset into a training set and a test set. The training set is used to train your model, while the test set is used to evaluate its performance on unseen data.\n",
    "#### Pipeline\n",
    "pipeline is a convenient way to chain multiple data preprocessing steps and machine learning algorithms together. The scikit-learn library provides the Pipeline class, which allows you to define and execute a sequence of transformations and estimators in a systematic manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Independent and dependent features\n",
    "df = pd.read_csv('C:/pwskills_python_codes/DiamondPricePrediction/notebooks/data/gemstone.csv')\n",
    "df=df.drop(['id'],axis=1)\n",
    "X = df.drop(['price'],axis=1)\n",
    "Y = df[['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating numerical and categorical variables\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "numerical_cols = X.select_dtypes(exclude='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['carat', 'depth', 'table', 'x', 'y', 'z'], dtype='object')\n",
      "Index(['cut', 'color', 'clarity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(numerical_cols)\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom ranking for each ordinal variable\n",
    "cut_categories = ['Fair', 'Good', 'Very Good','Premium','Ideal']\n",
    "color_categories = ['D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "clarity_categories = ['I1','SI2','SI1','VS2','VS1','VVS2','VVS1','IF']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    ('remove_features', FunctionTransformer((lambda X: X.drop(['x', 'y', 'z'], axis=1)), validate=False)),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Categorigal Pipeline\n",
    "cat_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinalencoder', OrdinalEncoder(categories=[cut_categories, color_categories, clarity_categories])),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "('num_pipeline',num_pipeline,numerical_cols),\n",
    "('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=[['carat', 'depth', 'table', 'cut', 'color', 'clarity']])\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=[['carat', 'depth', 'table', 'cut', 'color', 'clarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.975439</td>\n",
       "      <td>-0.849607</td>\n",
       "      <td>-0.121531</td>\n",
       "      <td>0.874076</td>\n",
       "      <td>1.528722</td>\n",
       "      <td>1.352731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235195</td>\n",
       "      <td>1.833637</td>\n",
       "      <td>-0.121531</td>\n",
       "      <td>-2.144558</td>\n",
       "      <td>-0.935071</td>\n",
       "      <td>-0.646786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.494617</td>\n",
       "      <td>0.815855</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>-0.132136</td>\n",
       "      <td>0.296826</td>\n",
       "      <td>0.686225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.018676</td>\n",
       "      <td>0.260701</td>\n",
       "      <td>0.921131</td>\n",
       "      <td>-0.132136</td>\n",
       "      <td>0.296826</td>\n",
       "      <td>0.019720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.953821</td>\n",
       "      <td>-0.664555</td>\n",
       "      <td>-0.642862</td>\n",
       "      <td>0.874076</td>\n",
       "      <td>2.144670</td>\n",
       "      <td>1.352731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat     depth     table       cut     color   clarity\n",
       "0 -0.975439 -0.849607 -0.121531  0.874076  1.528722  1.352731\n",
       "1  0.235195  1.833637 -0.121531 -2.144558 -0.935071 -0.646786\n",
       "2  0.494617  0.815855  0.399800 -0.132136  0.296826  0.686225\n",
       "3 -1.018676  0.260701  0.921131 -0.132136  0.296826  0.019720\n",
       "4 -0.953821 -0.664555 -0.642862  0.874076  2.144670  1.352731"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Model Training Performance\n",
      "RMSE: 827.2447627721448\n",
      "MAE: 418.28553521680266\n",
      "R2 score for test 95.7988684968339\n",
      "R2 score for train 99.83697395085885\n",
      "===================================\n",
      "\n",
      "\n",
      "LinearRegression\n",
      "Model Training Performance\n",
      "RMSE: 1099.6943843143683\n",
      "MAE: 806.3805022561628\n",
      "R2 score for test 92.57592692715887\n",
      "R2 score for train 92.52748141456539\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model Training Performance\n",
      "RMSE: 1099.7070571865745\n",
      "MAE: 806.0476384650286\n",
      "R2 score for test 92.57575581621613\n",
      "R2 score for train 92.52742700593768\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model Training Performance\n",
      "RMSE: 1099.6945713391974\n",
      "MAE: 806.3751566214534\n",
      "R2 score for test 92.57592440193709\n",
      "R2 score for train 92.52748140478235\n",
      "===================================\n",
      "\n",
      "\n",
      "Elasticnet\n",
      "Model Training Performance\n",
      "RMSE: 1831.6608029990882\n",
      "MAE: 1239.9971996118236\n",
      "R2 score for test 79.4037418412659\n",
      "R2 score for train 79.36759398085746\n",
      "===================================\n",
      "\n",
      "\n",
      "KNN\n",
      "Model Training Performance\n",
      "RMSE: 724.1472091506897\n",
      "MAE: 395.9440900950545\n",
      "R2 score for test 96.7807704482506\n",
      "R2 score for train 97.84823635094692\n",
      "===================================\n",
      "\n",
      "\n",
      "XBG\n",
      "Model Training Performance\n",
      "RMSE: 590.451781137204\n",
      "MAE: 301.2311878590598\n",
      "R2 score for test 97.85973722837727\n",
      "R2 score for train 98.28988163091499\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\AppData\\Local\\Temp\\ipykernel_15068\\91300290.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train,y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest\n",
      "Model Training Performance\n",
      "RMSE: 637.6597693464169\n",
      "MAE: 329.6385622266084\n",
      "R2 score for test 97.50381793347167\n",
      "R2 score for train 99.53918814982065\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost\n",
      "Model Training Performance\n",
      "RMSE: 1198.8984069452056\n",
      "MAE: 790.1264395575438\n",
      "R2 score for test 91.17605099654375\n",
      "R2 score for train 91.23840224220335\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankit\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_gb.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradientboost\n",
      "Model Training Performance\n",
      "RMSE: 619.7769284774103\n",
      "MAE: 333.5549661325968\n",
      "R2 score for test 97.6418629923036\n",
      "R2 score for train 97.65249864571588\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train multiple models\n",
    "## Model Ecaluation\n",
    "models={\n",
    "    'Decision Tree' :DecisionTreeRegressor(),\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(),\n",
    "    'Elasticnet':ElasticNet(),\n",
    "    'KNN':KNeighborsRegressor(),\n",
    "    'XBG':XGBRegressor(),\n",
    "    'RandomForest':RandomForestRegressor(),\n",
    "    'Adaboost':AdaBoostRegressor(),\n",
    "    'Gradientboost':GradientBoostingRegressor()\n",
    "}\n",
    "trained_model_list=[]\n",
    "model_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    mae, rmse, r2_square=evaluate_model(y_test,y_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"RMSE:\",rmse)\n",
    "    print(\"MAE:\",mae)\n",
    "    print(\"R2 score for test\",r2_square*100)\n",
    "    print(\"R2 score for train\", r2_score(y_train, model.predict(X_train))*100)\n",
    "\n",
    "    r2_list.append(r2_square)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Decision Tree',\n",
       " 'LinearRegression',\n",
       " 'Lasso',\n",
       " 'Ridge',\n",
       " 'Elasticnet',\n",
       " 'KNN',\n",
       " 'XBG',\n",
       " 'RandomForest',\n",
       " 'Adaboost',\n",
       " 'Gradientboost']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
